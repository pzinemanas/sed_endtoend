# CREATED: 4/6/17 10:54 by Justin Salamon <justin.salamon@nyu.edu>

import pandas as pd
import os
import sed_eval
import gzip
import glob
import pickle
import librosa
import soundfile as sf

import numpy as np
import keras
import random
import math
from scipy.signal import hanning

from sklearn.preprocessing import StandardScaler,MinMaxScaler
    
class DataGenerator(keras.utils.Sequence):
    'Generates data for Keras'
    def __init__(self, list_IDs, labels, files_batch=3, n_channels=1,scaler=[],label_list=[],train=True,
                 n_classes=10, shuffle=True,path='./',sequence_time=1.0, sequence_hop_time=0.5,frames=False,normalize_energy=False,
                      audio_hop=882, audio_win=1764,n_fft=2048,sr=44100,mel_bands=128,normalize=' ',get_annotations=True,alpha=10**4):
        'Initialization'
        ## min_v y max_v se deben calcular antes de inicializar.

        self.files_batch = files_batch # cuantos archivos hay por batch si es 3 da batch_size=30
        self.labels = labels
        self.list_IDs = list_IDs
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.shuffle = shuffle
        self.on_epoch_end()
        self.path = path
        self.sr = sr
        self.n_fft = n_fft
        self.mel_bands = mel_bands
        self.audio_hop = audio_hop
        self.audio_win = audio_win
        self.mel_basis = librosa.filters.mel(sr,n_fft,mel_bands,htk=True)#,htk=False)
        self.mel_basis = self.mel_basis**2 #PARA CALCULAR BIEN LA ENERGIA
        self.sequence_frames = int(sequence_time * sr / float(audio_hop))
        self.sequence_hop = int(sequence_hop_time * sr / float(audio_hop))
        self.sequence_samples = int(sequence_time * sr)
        self.sequence_hop_samples = int(sequence_hop_time * sr)
        self.hop_time = audio_hop / float(sr)
        self.label_list = label_list
        self.normalize = normalize
        self.sequence_hop_time = sequence_hop_time
        self.scaler = scaler
        self.frames = frames
        self.get_annotations = get_annotations
        self.alpha = alpha
        self.normalize_energy = normalize_energy


        mels = []
        if train:
            for n,ID in enumerate(self.list_IDs):
                audio,sr = sf.read(ID)
                if len(audio.shape) > 1:
                    audio = audio[:,0]
                #audio = np.ascontiguousarray(audio)
                #Normalizo todo el archivo
#                audio = audio/np.amax(audio)
#                stft = np.abs(librosa.core.stft(audio, n_fft=self.n_fft, hop_length=self.audio_hop, win_length=self.audio_win))**2  
#                melspec = self.mel_basis.dot(stft)
#                melspec = librosa.core.power_to_db(melspec)

#                mels.append(melspec.T)


                #Normalizo por segmentos de 1 seg.
                for i in np.arange(0,len(audio)-self.sequence_samples+1,self.sequence_hop_samples):
                    if self.normalize == 'minmax':
                       audio_slice = audio[i:i+self.sequence_samples]/np.amax(audio[i:i+self.sequence_samples])
                      # audio_slice = audio[i:i+self.sequence_samples]
#                    elif self.normalize == 'standard':
#                       audio_slice = (audio[i:i+self.sequence_samples]-np.mean(audio[i:i+self.sequence_samples]))/np.std(audio[i:i+self.sequence_samples])
                    else:
                       audio_slice = audio[i:i+self.sequence_samples]
                    audio_slice[np.isinf(audio_slice)] = 0
                    audio_slice[np.isnan(audio_slice)] = 0
                    if np.isfinite(audio_slice).all() == False:
                        print(audio_slice)
                    stft = np.abs(librosa.core.stft(audio_slice, n_fft=self.n_fft, hop_length=self.audio_hop, win_length=self.audio_win))**2  
    #                stft = np.abs(np.fft.fft(f,n=self.n_fft,axis=0)[:self.n_fft/2+1])**
                    melspec = self.mel_basis.dot(stft)
                    #if self.normalize_energy:
                    melspec = melspec/(self.n_fft/2+1) #PARA NORMALIZAR ENERGIA
                    melspec = melspec*self.alpha
                    melspec = librosa.core.power_to_db(melspec)
#
                    mels.append(melspec.T)

            mel_all = []
            for mel in mels:
                mel_all.extend(mel)

            mel_all = np.asarray(mel_all)
            print(mel_all.shape)
            #mels = np.reshape(mels,(-1,self.mel_bands))
            #print(mels.shape)
            if normalize == 'standard':
                print('Normalize Standard')
                #mean = np.mean(mels,axis=(0,2))
                #std = np.std(mels,axis=(0,2))
                #mean = np.expand_dims(mean,axis=1) 
                #std = np.expand_dims(std,axis=1) 
                #self.scaler = [mean,std]
                self.scaler = StandardScaler()
                self.scaler.fit(mel_all)
                assert len(self.scaler.mean_) == self.mel_bands
            if normalize == 'minmax':
                print('Normalize MinMax')
                min_v = np.amin(mel_all)#,axis=(0,2))
                max_v = np.amax(mel_all)#,axis=(0,2))
              #  min_v = np.expand_dims(min_v,axis=1) 
              #  max_v = np.expand_dims(max_v,axis=1) 
                self.scaler = [min_v,max_v]
                #self.scaler = MinMaxScaler(feature_range=(-1,1))
                #self.scaler.fit(mels)
                #assert len(self.scaler.min_) == self.mel_bands
            self.scaler2 = StandardScaler()
            self.scaler2.fit(mel_all)                
#	    self.scaler2 = self.scaler
    def __len__(self):
        'Denotes the number of batches per epoch'
        return int(np.floor(len(self.list_IDs) / self.files_batch))

    def __getitem__(self, index):
        'Generate one batch of data'
        # Generate indexes of the batch
        indexes = self.indexes[index*self.files_batch:(index+1)*self.files_batch]

        # Find list of IDs
        list_IDs_temp = [self.list_IDs[k] for k in indexes]

        # Generate data
        X, y = self.__data_generation(list_IDs_temp)

        return X, y

    def on_epoch_end(self):
        'Updates indexes after each epoch'
        self.indexes = np.arange(len(self.list_IDs))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)

    def __data_generation(self, list_IDs_temp):
        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)
        # Initialization
        #X = np.empty((self.batch_size, *self.dim, self.n_channels))
        #y = np.empty((self.batch_size,self.n_classes), dtype=int)

        # Generate data
        X = []
        yt= []
        mel = []
        id_t = []
        S = []
        
        window = hanning(self.audio_win)

        for i, ID in enumerate(list_IDs_temp):
            label_file = self.labels[ID]
            
            if self.get_annotations:            
            
                labels = pd.read_csv(label_file, delimiter='\t', header=None)
                labels.columns = ['event_onset', 'event_offset', 'event_label']
            else:
                labels = pd.DataFrame({'event_onset' : []})
    
            # get y first
 #           event_roll = sed_eval.util.event_roll.event_list_to_event_roll(
 #               labels.to_dict('records'), event_label_list=self.label_list,
 #               time_resolution=self.sequence_hop_time)#self.hop_time)

            audio,sr = sf.read(ID)
            if len(audio.shape) > 1:
                audio = audio[:,0]
            #audio = np.ascontiguousarray(audio)
            ####Normalizo todo el archivo:
#            if self.normalize == 'minmax':
#               audio = audio/np.amax(audio)
#            if self.normalize == 'standard':
#               audio = (audio-np.mean(audio))/np.std(audio)

#            stft = np.abs(librosa.core.stft(audio, n_fft=self.n_fft, hop_length=self.audio_hop, win_length=self.audio_win))**2  
#            melspec = self.mel_basis.dot(stft)
#            melspec = librosa.core.power_to_db(melspec)

#            if self.normalize == 'minmax':
#                melspec = (melspec.T-self.scaler[0])/(self.scaler[1]-self.scaler[0])
#                melspec = melspec.T
                #mel.append(self.scaler.transform(melspec.T))
#            if self.normalize == 'standard':
                #mel.append((melspec-self.scaler[0])/(self.scaler[1]))
#                melspec = self.scaler.transform(melspec.T)
#                melspec = melspec.T                

            ####

            event_roll = np.zeros((int(math.ceil((len(audio)-self.sequence_samples+1)/ float(self.sequence_hop_samples))), len(self.label_list)))

    # Fill-in event_roll
            for event in labels.to_dict('records'):
                pos = self.label_list.index(event['event_label'])

                event_onset = event['event_onset']
                event_offset = event['event_offset']
 
                onset = int(math.floor(event_onset * 1 / float(self.sequence_hop_time)))
                offset = int(math.ceil(event_offset * 1 / float(self.sequence_hop_time)))
 
                event_roll[onset:offset, pos] = 1



#            if len(event_roll) != int(len(audio)/self.sequence_hop_samples):
 #                  z = np.zeros((len(audio)/self.sequence_hop_samples-len(event_roll),len(self.label_list)))
  #                 event_roll = np.concatenate((event_roll,z),axis=0)

            

#                print(event_roll.shape)
            # Carve out x's and get aligned y's

#            for i in np.arange(0, #+ self.sequence_offset,  #i=0,25,50... por muestras: j=0,22500,...
   #         audio,sr = sf.read(ID)

 #                              melspec.shape[1] - 1 * self.sequence_frames,
  #                             self.sequence_hop):
            for i in np.arange(0,len(audio)-self.sequence_samples+1,self.sequence_hop_samples):
                audio_slice = audio[i:i+self.sequence_samples]

                #### Normalizo por slices
                if self.normalize == 'minmax':
                   audio_slice = audio[i:i+self.sequence_samples]/np.amax(audio[i:i+self.sequence_samples])
 #               elif self.normalize == 'standard':
  #                 audio_slice = (audio[i:i+self.sequence_samples]-np.mean(audio[i:i+self.sequence_samples]))/np.std(audio[i:i+self.sequence_samples])
                else:
                   audio_slice = audio[i:i+self.sequence_samples]
                ######
                audio_slice[np.isinf(audio_slice)] = 0
                audio_slice[np.isnan(audio_slice)] = 0
                audio_slice_pad = np.pad(audio_slice, int(self.n_fft // 2), mode='reflect')

                if self.frames:
                    f = librosa.util.frame(audio_slice_pad, frame_length=self.audio_win, hop_length=self.audio_hop)                   

                    W = np.zeros_like(f)
                    for j in range(W.shape[1]):
                        W[:,j] = window
                    f = f*W
                    X.append(f.T)                 
                else:
                    X.append(audio_slice)  
                   

                #### Normalizo por slices
                stft = np.abs(librosa.core.stft(audio_slice_pad, n_fft=self.n_fft, hop_length=self.audio_hop, win_length=self.audio_win, center=False))**2  #, center=not self.frames
                stft = stft/(self.n_fft/2+1)
                S.append(stft)
#		print(stft.shape,f.shape)
#		stft = np.abs(np.fft.fft(f,n=self.n_fft,axis=0)[:self.n_fft/2+1])**2
#		print(stft1,stft)
#		print(stft.shape)
                melspec = self.mel_basis.dot(stft)
                #if self.normalize_energy:
                #melspec = melspec/(self.n_fft/2+1) #PARA NORMALIZAR ENERGIA
                melspec = melspec*self.alpha
                melspec = librosa.core.power_to_db(melspec)
#
                if self.normalize == 'minmax':
                    mel.append(2*((melspec.T-self.scaler[0])/(self.scaler[1]-self.scaler[0])-0.5))
                    #mel.append(self.scaler.transform(melspec.T))
                elif self.normalize == 'standard':
                    #mel.append((melspec-self.scaler[0])/(self.scaler[1]))
                    mel.append(self.scaler.transform(melspec.T))
                else:
                    mel.append(melspec.T)
                ######

                # Get y
                j = int(i/float(self.sequence_hop_samples))
                    
#                mel.append(melspec[:,j*self.sequence_hop: j*self.sequence_hop + self.sequence_frames].T)        
                

                #j = int(i*self.sequence_hop/float(22500))
                y = event_roll[j, :]
                #y = (event_roll[j:j + self.sequence_frames, :]).tolist()
                #if len(y) != self.sequence_frames:
                #    y.extend(np.zeros((self.sequence_frames - len(y), len(self.label_list))))

#                if len(y) != self.sequence_frames:
 #                   y.extend(np.zeros((self.sequence_frames - len(y), len(self.label_list))))

               # y = np.asarray(y)
                #assert y.shape == (self.sequence_frames, len(self.label_list))
#                y = y.any(axis=0) * 1
#                print(j,y)
                assert y.shape == (len(self.label_list),)
                yt.append(y)
                # Get id
                id = [ID, i]
                id_t.append(id)

        X = np.asarray(X)
        print(X.shape)        
        
        yt = np.asarray(yt)
        mel = np.asarray(mel)
        S = np.asarray(S)
        S = np.transpose(S,(0,2,1))

        X = np.expand_dims(X, -1)
        #X = np.transpose(X,(0,2,1))
    
        #mel = np.expand_dims(mel, -1)

        #return X, [yt,mel]
        #return X, mel
	return X,S,mel,yt
    def return_all(self):

        X,S,mel,y = self.__data_generation(self.list_IDs)

        return X,S,mel,y

    def return_random(self):

        j = random.randint(0,len(self.list_IDs)-1)
        
        X,S,mel,y = self.__data_generation([self.list_IDs[j]])

        return X,S,mel,y

    def get_scaler(self):
        return self.scaler

    def get_scaler2(self):
        return self.scaler2
