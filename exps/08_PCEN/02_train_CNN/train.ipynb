{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train S-CNN baseline with PCEN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0,'../../..')\n",
    "from sed_endtoend.cnn.model import build_custom_cnn\n",
    "from keras.optimizers import Adam\n",
    "from sed_endtoend.callbacks import MetricsCallback\n",
    "from sed_endtoend.data_generator import DataGenerator, Scaler\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from params import *\n",
    "\n",
    "# files parameters\n",
    "Nfiles = None\n",
    "resume = False\n",
    "load_subset = Nfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making training generator\n",
      "Making validation generator\n",
      "Getting validation data\n",
      "0.0 %\n",
      "10.0 %\n",
      "20.0 %\n",
      "30.0 %\n",
      "40.0 %\n",
      "50.0 %\n",
      "60.0 %\n",
      "70.0 %\n",
      "80.0 %\n",
      "90.0 %\n",
      "Getting training data\n",
      "0.0 %\n",
      "10.0 %\n",
      "20.0 %\n",
      "30.0 %\n",
      "40.0 %\n",
      "50.0 %\n",
      "60.0 %\n",
      "70.0 %\n",
      "80.0 %\n",
      "90.0 %\n",
      "Founding standard scaler\n"
     ]
    }
   ],
   "source": [
    "params = {'sequence_time': sequence_time, 'sequence_hop_time':sequence_hop_time,\n",
    "          'label_list':label_list,'audio_hop':audio_hop, 'audio_win':audio_win,\n",
    "          'n_fft':n_fft,'sr':sr,'mel_bands':mel_bands,'normalize':normalize_data, \n",
    "          'frames':frames,'get_annotations':get_annotations, 'dataset': dataset}\n",
    "\n",
    "sequence_frames = int(np.ceil(sequence_time*sr/audio_hop))\n",
    "\n",
    "# Datasets\n",
    "labels = {}# Labels\n",
    "\n",
    "train_files = sorted(glob.glob(os.path.join(audio_folder,'train', '*.wav')))\n",
    "val_files = sorted(glob.glob(os.path.join(audio_folder,'validate', '*.wav')))\n",
    "\n",
    "if load_subset is not None:\n",
    "    train_files = train_files[:load_subset]\n",
    "    val_files = val_files[:load_subset]\n",
    "\n",
    "train_labels = {}\n",
    "train_mel = {}\n",
    "val_labels = {}\n",
    "val_mel = {}\n",
    "\n",
    "for n,id in enumerate(train_files):\n",
    "    labels[id] = os.path.join(label_folder, 'train',os.path.basename(id).replace('.wav','.txt'))\n",
    "for id in val_files:\n",
    "    labels[id] = os.path.join(label_folder, 'validate',os.path.basename(id).replace('.wav','.txt'))\n",
    "\n",
    "params['normalize_energy'] = False\n",
    "params['convert_to_dB'] = False\n",
    "    \n",
    "# Generators\n",
    "print('Making training generator')\n",
    "training_generator = DataGenerator(train_files, labels, **params)\n",
    "\n",
    "params['sequence_hop_time'] = sequence_time # To calculate F1_1s\n",
    "\n",
    "print('Making validation generator')\n",
    "validation_generator = DataGenerator(val_files, labels, **params)\n",
    "\n",
    "print('Getting validation data')\n",
    "\n",
    "\n",
    "_,_,mel_val,y_val = validation_generator.return_all()\n",
    "print('Getting training data')\n",
    "\n",
    "_,_,mel_train,y_train = training_generator.return_all()\n",
    "\n",
    "for j in range(mel_train.shape[0]):\n",
    "    #mel_power = librosa.core.db_to_power()\n",
    "\n",
    "    mel_train[j] = librosa.pcen(mel_train[j],sr=sr, hop_length=audio_hop, \n",
    "                                gain=alpha2, bias=delta, power=r, time_constant=time_constant) \n",
    "\n",
    "for j in range(mel_val.shape[0]):\n",
    "    #mel_power = librosa.core.db_to_power(mel_val[j])    \n",
    "    mel_val[j] = librosa.pcen(mel_val[j],sr=sr, hop_length=audio_hop, \n",
    "                                gain=alpha2, bias=delta, power=r, time_constant=time_constant) \n",
    "\n",
    "print('Founding standard scaler')\n",
    "standard_scaler = Scaler(normalizer='standard')\n",
    "standard_scaler.fit(mel_train)\n",
    "standard_scaler_sklearn = standard_scaler.get_scaler()\n",
    "mean= standard_scaler_sklearn.mean_\n",
    "scale = standard_scaler_sklearn.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 44, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 44, 128)           512       \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 44, 128, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 40, 124, 128)      3328      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 20, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 20, 62, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 58, 128)       409728    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 8, 29, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 8, 29, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 4, 25, 128)        409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 4, 25, 128)        512       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               1638528   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,481,162\n",
      "Trainable params: 2,480,138\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "\n",
      "Fitting model...\n",
      "Epoch 1/101\n",
      "60000/60000 [==============================] - 28s 473us/step - loss: 0.3819\n",
      "F1 = 0.0000, ER = 1.0000 - Best val F1s: 0.0000 (0)\n",
      "\n",
      "Epoch 2/101\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 0.3457\n",
      "F1 = 0.0000, ER = 1.0000 - Best val F1s: 0.0000 (0)\n",
      "\n",
      "Epoch 3/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.3404\n",
      "F1 = 0.0000, ER = 1.0000 - Best val F1s: 0.0000 (0)\n",
      "\n",
      "Epoch 4/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.3381\n",
      "F1 = 0.0000, ER = 1.0000 - Best val F1s: 0.0000 (0)\n",
      "\n",
      "Epoch 5/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3364\n",
      "F1 = 0.0000, ER = 1.0000 - Best val F1s: 0.0000 (0)\n",
      "\n",
      "Epoch 6/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3339\n",
      "F1 = 0.0000, ER = 1.0000 - Best val F1s: 0.0000 (0)\n",
      "\n",
      "Epoch 7/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.3319\n",
      "F1 = 0.0000, ER = 1.0000 - Best val F1s: 0.0000 (0)\n",
      "\n",
      "Epoch 8/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3282\n",
      "F1 = 0.0000, ER = 1.0000 - Best val F1s: 0.0000 (0)\n",
      "\n",
      "Epoch 9/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3269\n",
      "F1 = 0.0000, ER = 1.0000 - Best val F1s: 0.0000 (0)\n",
      "\n",
      "Epoch 10/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3244\n",
      "F1 = 0.0001, ER = 1.0000 -  Best val F1s: 0.0001 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 11/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3224\n",
      "F1 = 0.0000, ER = 1.0000 - Best val F1s: 0.0001 (9)\n",
      "\n",
      "Epoch 12/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3204\n",
      "F1 = 0.0022, ER = 0.9989 -  Best val F1s: 0.0022 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 13/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.3193\n",
      "F1 = 0.0036, ER = 0.9982 -  Best val F1s: 0.0036 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 14/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3174\n",
      "F1 = 0.0080, ER = 0.9960 -  Best val F1s: 0.0080 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 15/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3140\n",
      "F1 = 0.0286, ER = 0.9853 -  Best val F1s: 0.0286 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 16/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3096\n",
      "F1 = 0.0514, ER = 0.9734 -  Best val F1s: 0.0514 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 17/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.3066\n",
      "F1 = 0.0659, ER = 0.9657 -  Best val F1s: 0.0659 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 18/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.3026\n",
      "F1 = 0.1316, ER = 0.9277 -  Best val F1s: 0.1316 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 19/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2986\n",
      "F1 = 0.1045, ER = 0.9442 - Best val F1s: 0.1316 (17)\n",
      "\n",
      "Epoch 20/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2928\n",
      "F1 = 0.1401, ER = 0.9227 -  Best val F1s: 0.1401 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 21/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2855\n",
      "F1 = 0.1638, ER = 0.9080 -  Best val F1s: 0.1638 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 22/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2783\n",
      "F1 = 0.2489, ER = 0.8502 -  Best val F1s: 0.2489 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 23/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2711\n",
      "F1 = 0.3019, ER = 0.8109 -  Best val F1s: 0.3019 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 24/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.2652\n",
      "F1 = 0.2865, ER = 0.8113 - Best val F1s: 0.3019 (22)\n",
      "\n",
      "Epoch 25/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.2600\n",
      "F1 = 0.3413, ER = 0.7829 -  Best val F1s: 0.3413 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 26/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2550\n",
      "F1 = 0.3450, ER = 0.7756 -  Best val F1s: 0.3450 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 27/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.2513\n",
      "F1 = 0.3830, ER = 0.7422 -  Best val F1s: 0.3830 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 28/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.2472\n",
      "F1 = 0.4057, ER = 0.7245 -  Best val F1s: 0.4057 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 29/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2431\n",
      "F1 = 0.4178, ER = 0.7105 -  Best val F1s: 0.4178 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 30/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.2396\n",
      "F1 = 0.4326, ER = 0.6987 -  Best val F1s: 0.4326 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 31/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.2358\n",
      "F1 = 0.4368, ER = 0.6933 -  Best val F1s: 0.4368 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 32/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.2318\n",
      "F1 = 0.4539, ER = 0.6734 -  Best val F1s: 0.4539 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 33/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.2295\n",
      "F1 = 0.4482, ER = 0.6783 - Best val F1s: 0.4539 (31)\n",
      "\n",
      "Epoch 34/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2271\n",
      "F1 = 0.4505, ER = 0.6765 - Best val F1s: 0.4539 (31)\n",
      "\n",
      "Epoch 35/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2231\n",
      "F1 = 0.4628, ER = 0.6650 -  Best val F1s: 0.4628 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 36/101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2205\n",
      "F1 = 0.4615, ER = 0.6608 - Best val F1s: 0.4628 (34)\n",
      "\n",
      "Epoch 37/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2177\n",
      "F1 = 0.4792, ER = 0.6428 -  Best val F1s: 0.4792 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 38/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2146\n",
      "F1 = 0.4699, ER = 0.6564 - Best val F1s: 0.4792 (36)\n",
      "\n",
      "Epoch 39/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2121\n",
      "F1 = 0.4750, ER = 0.6450 - Best val F1s: 0.4792 (36)\n",
      "\n",
      "Epoch 40/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.2098\n",
      "F1 = 0.4698, ER = 0.6504 - Best val F1s: 0.4792 (36)\n",
      "\n",
      "Epoch 41/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2071\n",
      "F1 = 0.4811, ER = 0.6363 -  Best val F1s: 0.4811 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 42/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.2043\n",
      "F1 = 0.4849, ER = 0.6294 -  Best val F1s: 0.4849 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 43/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2030\n",
      "F1 = 0.4880, ER = 0.6291 -  Best val F1s: 0.4880 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 44/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.2001\n",
      "F1 = 0.4897, ER = 0.6265 -  Best val F1s: 0.4897 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 45/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1981\n",
      "F1 = 0.5034, ER = 0.6110 -  Best val F1s: 0.5034 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 46/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1951\n",
      "F1 = 0.4886, ER = 0.6211 - Best val F1s: 0.5034 (44)\n",
      "\n",
      "Epoch 47/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1944\n",
      "F1 = 0.4857, ER = 0.6206 - Best val F1s: 0.5034 (44)\n",
      "\n",
      "Epoch 48/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1912\n",
      "F1 = 0.4945, ER = 0.6193 - Best val F1s: 0.5034 (44)\n",
      "\n",
      "Epoch 49/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1895\n",
      "F1 = 0.5005, ER = 0.6036 - Best val F1s: 0.5034 (44)\n",
      "\n",
      "Epoch 50/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1882\n",
      "F1 = 0.4992, ER = 0.6116 - Best val F1s: 0.5034 (44)\n",
      "\n",
      "Epoch 51/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1851\n",
      "F1 = 0.5062, ER = 0.5950 -  Best val F1s: 0.5062 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 52/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1837\n",
      "F1 = 0.5011, ER = 0.6019 - Best val F1s: 0.5062 (50)\n",
      "\n",
      "Epoch 53/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1824\n",
      "F1 = 0.5127, ER = 0.5951 -  Best val F1s: 0.5127 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 54/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1797\n",
      "F1 = 0.5016, ER = 0.5952 - Best val F1s: 0.5127 (52)\n",
      "\n",
      "Epoch 55/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1784\n",
      "F1 = 0.5112, ER = 0.5873 - Best val F1s: 0.5127 (52)\n",
      "\n",
      "Epoch 56/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1759\n",
      "F1 = 0.5099, ER = 0.5902 - Best val F1s: 0.5127 (52)\n",
      "\n",
      "Epoch 57/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1749\n",
      "F1 = 0.5134, ER = 0.5827 -  Best val F1s: 0.5134 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 58/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1739\n",
      "F1 = 0.5137, ER = 0.5810 -  Best val F1s: 0.5137 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 59/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1713\n",
      "F1 = 0.5101, ER = 0.5849 - Best val F1s: 0.5137 (57)\n",
      "\n",
      "Epoch 60/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1714\n",
      "F1 = 0.5230, ER = 0.5723 -  Best val F1s: 0.5230 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 61/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1683\n",
      "F1 = 0.5089, ER = 0.5806 - Best val F1s: 0.5230 (59)\n",
      "\n",
      "Epoch 62/101\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 0.1675\n",
      "F1 = 0.5166, ER = 0.5788 - Best val F1s: 0.5230 (59)\n",
      "\n",
      "Epoch 63/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1662\n",
      "F1 = 0.5051, ER = 0.5886 - Best val F1s: 0.5230 (59)\n",
      "\n",
      "Epoch 64/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1641\n",
      "F1 = 0.5036, ER = 0.5893 - Best val F1s: 0.5230 (59)\n",
      "\n",
      "Epoch 65/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1629\n",
      "F1 = 0.5090, ER = 0.5869 - Best val F1s: 0.5230 (59)\n",
      "\n",
      "Epoch 66/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1611\n",
      "F1 = 0.5141, ER = 0.5756 - Best val F1s: 0.5230 (59)\n",
      "\n",
      "Epoch 67/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1601\n",
      "F1 = 0.5146, ER = 0.5774 - Best val F1s: 0.5230 (59)\n",
      "\n",
      "Epoch 68/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1588\n",
      "F1 = 0.5146, ER = 0.5745 - Best val F1s: 0.5230 (59)\n",
      "\n",
      "Epoch 69/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1578\n",
      "F1 = 0.5132, ER = 0.5785 - Best val F1s: 0.5230 (59)\n",
      "\n",
      "Epoch 70/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1569\n",
      "F1 = 0.5222, ER = 0.5608 - Best val F1s: 0.5230 (59)\n",
      "\n",
      "Epoch 71/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1544\n",
      "F1 = 0.5151, ER = 0.5760 - Best val F1s: 0.5230 (59)\n",
      "\n",
      "Epoch 72/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1535\n",
      "F1 = 0.5029, ER = 0.5924 - Best val F1s: 0.5230 (59)\n",
      "\n",
      "Epoch 73/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1527\n",
      "F1 = 0.5111, ER = 0.5813 - Best val F1s: 0.5230 (59)\n",
      "\n",
      "Epoch 74/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1504\n",
      "F1 = 0.5217, ER = 0.5605 - Best val F1s: 0.5230 (59)\n",
      "\n",
      "Epoch 75/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1500\n",
      "F1 = 0.5153, ER = 0.5663 - Best val F1s: 0.5230 (59)\n",
      "\n",
      "Epoch 76/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1490\n",
      "F1 = 0.5231, ER = 0.5583 -  Best val F1s: 0.5231 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 77/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1476\n",
      "F1 = 0.5194, ER = 0.5664 - Best val F1s: 0.5231 (75)\n",
      "\n",
      "Epoch 78/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1476\n",
      "F1 = 0.5224, ER = 0.5644 - Best val F1s: 0.5231 (75)\n",
      "\n",
      "Epoch 79/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1459\n",
      "F1 = 0.5082, ER = 0.5713 - Best val F1s: 0.5231 (75)\n",
      "\n",
      "Epoch 80/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1443\n",
      "F1 = 0.5174, ER = 0.5656 - Best val F1s: 0.5231 (75)\n",
      "\n",
      "Epoch 81/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1440\n",
      "F1 = 0.5138, ER = 0.5677 - Best val F1s: 0.5231 (75)\n",
      "\n",
      "Epoch 82/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1429\n",
      "F1 = 0.5175, ER = 0.5716 - Best val F1s: 0.5231 (75)\n",
      "\n",
      "Epoch 83/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1413\n",
      "F1 = 0.5144, ER = 0.5661 - Best val F1s: 0.5231 (75)\n",
      "\n",
      "Epoch 84/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1407\n",
      "F1 = 0.5154, ER = 0.5678 - Best val F1s: 0.5231 (75)\n",
      "\n",
      "Epoch 85/101\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 0.1402\n",
      "F1 = 0.5226, ER = 0.5537 - Best val F1s: 0.5231 (75)\n",
      "\n",
      "Epoch 86/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1388\n",
      "F1 = 0.5204, ER = 0.5555 - Best val F1s: 0.5231 (75)\n",
      "\n",
      "Epoch 87/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1374\n",
      "F1 = 0.5121, ER = 0.5747 - Best val F1s: 0.5231 (75)\n",
      "\n",
      "Epoch 88/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1365\n",
      "F1 = 0.5238, ER = 0.5449 -  Best val F1s: 0.5238 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 89/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1367\n",
      "F1 = 0.5236, ER = 0.5542 - Best val F1s: 0.5238 (87)\n",
      "\n",
      "Epoch 90/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1351\n",
      "F1 = 0.5152, ER = 0.5649 - Best val F1s: 0.5238 (87)\n",
      "\n",
      "Epoch 91/101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1343\n",
      "F1 = 0.5114, ER = 0.5699 - Best val F1s: 0.5238 (87)\n",
      "\n",
      "Epoch 92/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1339\n",
      "F1 = 0.5212, ER = 0.5603 - Best val F1s: 0.5238 (87)\n",
      "\n",
      "Epoch 93/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1326\n",
      "F1 = 0.5224, ER = 0.5556 - Best val F1s: 0.5238 (87)\n",
      "\n",
      "Epoch 94/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1320\n",
      "F1 = 0.5186, ER = 0.5677 - Best val F1s: 0.5238 (87)\n",
      "\n",
      "Epoch 95/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1306\n",
      "F1 = 0.5203, ER = 0.5612 - Best val F1s: 0.5238 (87)\n",
      "\n",
      "Epoch 96/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1299\n",
      "F1 = 0.5155, ER = 0.5549 - Best val F1s: 0.5238 (87)\n",
      "\n",
      "Epoch 97/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1297\n",
      "F1 = 0.5174, ER = 0.5535 - Best val F1s: 0.5238 (87)\n",
      "\n",
      "Epoch 98/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1288\n",
      "F1 = 0.5234, ER = 0.5551 - Best val F1s: 0.5238 (87)\n",
      "\n",
      "Epoch 99/101\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1275\n",
      "F1 = 0.5269, ER = 0.5507 -  Best val F1s: 0.5269 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 100/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1271\n",
      "F1 = 0.5171, ER = 0.5672 - Best val F1s: 0.5269 (98)\n",
      "\n",
      "Epoch 101/101\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.1264\n",
      "F1 = 0.5136, ER = 0.5680 - Best val F1s: 0.5269 (98)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nBuilding model...')\n",
    "\n",
    "sequence_samples = int(sequence_time*sr)\n",
    "\n",
    "model = build_custom_cnn(n_freq_cnn=mel_bands, n_frames_cnn=sequence_frames,large_cnn=large_cnn)\n",
    "\n",
    "# Init Batchnorm\n",
    "model.layers[1].set_weights([np.ones_like(mean),np.zeros_like(mean),mean,scale])\n",
    "model.summary()\n",
    "\n",
    "opt = Adam(lr=learning_rate)\n",
    "\n",
    "if resume:\n",
    "    print('Loading best weights and resuming...')\n",
    "    weights_best_file = os.path.join(expfolder, 'weights_best.hdf5')\n",
    "    model.load_weights(weights_best_file)\n",
    "\n",
    "# Fit model\n",
    "print('\\nFitting model...')\n",
    "\n",
    "if resume:\n",
    "    f1s_best = resume_f1_best\n",
    "\n",
    "metrics_callback = MetricsCallback(mel_val, y_val, 0, 0, os.path.join(expfolder, 'weights_best.hdf5'))\n",
    "csv_logger = CSVLogger(os.path.join(expfolder, 'training.log'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=opt)\n",
    "\n",
    "history = model.fit(x=mel_train, y=y_train, batch_size=2*batch_size,\n",
    "                            epochs=epochs, verbose=fit_verbose,\n",
    "                            validation_split=0.0,\n",
    "                            shuffle=True,\n",
    "                            callbacks=[metrics_callback,csv_logger])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
