{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SMel+S-CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import glob\n",
    "import sys\n",
    "sys.path.insert(0,'../..')\n",
    "\n",
    "from sed_endtoend.cnn.model import build_custom_cnn\n",
    "from sed_endtoend.smel.model import SMel\n",
    "from sed_endtoend.callbacks import MetricsCallback\n",
    "from sed_endtoend.concatenate_models import concatenate\n",
    "from sed_endtoend.data_generator import DataGenerator, Scaler\n",
    "from sed_endtoend.optimizer import Adam_Multipliers\n",
    "\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from params import *\n",
    "\n",
    "# files parameters\n",
    "Nfiles = None\n",
    "resume = False\n",
    "load_subset = Nfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making training generator\n",
      "Making validation generator\n",
      "Getting data\n",
      "0.0 %\n",
      "10.0 %\n",
      "20.0 %\n",
      "30.0 %\n",
      "40.0 %\n",
      "50.0 %\n",
      "60.0 %\n",
      "70.0 %\n",
      "80.0 %\n",
      "90.0 %\n",
      "0.0 %\n",
      "10.0 %\n",
      "20.0 %\n",
      "30.0 %\n",
      "40.0 %\n",
      "50.0 %\n",
      "60.0 %\n",
      "70.0 %\n",
      "80.0 %\n",
      "90.0 %\n",
      "Founding scaler\n"
     ]
    }
   ],
   "source": [
    "params = {'sequence_time': sequence_time, 'sequence_hop_time':sequence_hop_time,\n",
    "          'label_list':label_list,'audio_hop':audio_hop, 'audio_win':audio_win,\n",
    "          'n_fft':n_fft,'sr':sr,'mel_bands':mel_bands,'normalize':normalize_data, \n",
    "          'frames':frames,'get_annotations':get_annotations, 'dataset': dataset}\n",
    "\n",
    "sequence_frames = int(np.ceil(sequence_time*sr/audio_hop))\n",
    "\n",
    "# Datasets\n",
    "labels = {}# Labels\n",
    "\n",
    "train_files = sorted(glob.glob(os.path.join(audio_folder,'train', '*.wav')))\n",
    "val_files = sorted(glob.glob(os.path.join(audio_folder,'validate', '*.wav')))\n",
    "\n",
    "if load_subset is not None:\n",
    "    train_files = train_files[:load_subset]\n",
    "    val_files = val_files[:load_subset]\n",
    "\n",
    "train_labels = {}\n",
    "train_mel = {}\n",
    "val_labels = {}\n",
    "val_mel = {}\n",
    "\n",
    "\n",
    "for n,id in enumerate(train_files):\n",
    "    labels[id] = os.path.join(label_folder, 'train',os.path.basename(id).replace('.wav','.txt'))\n",
    "for id in val_files:\n",
    "    labels[id] = os.path.join(label_folder, 'validate',os.path.basename(id).replace('.wav','.txt'))\n",
    "\n",
    "# Generators\n",
    "print('Making training generator')\n",
    "training_generator = DataGenerator(train_files, labels, **params)\n",
    "\n",
    "params['sequence_hop_time'] = sequence_time # To calculate F1_1s\n",
    "\n",
    "print('Making validation generator')\n",
    "validation_generator = DataGenerator(val_files, labels, **params)\n",
    "\n",
    "print('Getting data')\n",
    "\n",
    "x_val,_,mel_val,y_val = validation_generator.return_all()\n",
    "x_train,_,mel_train,y_train = training_generator.return_all()\n",
    "\n",
    "print('Founding scaler')\n",
    "scaler = Scaler(normalizer=normalize_data)\n",
    "\n",
    "scaler.fit(mel_train)\n",
    "\n",
    "mel_train = scaler.transform(mel_train)\n",
    "mel_val = scaler.transform(mel_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1003 14:06:48.479002 139753170519808 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1003 14:06:49.293417 139753170519808 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1003 14:06:49.516024 139753170519808 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1003 14:06:49.809784 139753170519808 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1521: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1003 14:06:50.038204 139753170519808 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1003 14:06:50.135752 139753170519808 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1003 14:07:00.463468 139753170519808 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W1003 14:07:00.659028 139753170519808 deprecation.py:506] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1003 14:07:05.028266 139753170519808 deprecation_wrapper.py:119] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1003 14:07:05.039734 139753170519808 deprecation.py:323] From /home/pzinemanas/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 22050, 1024, 1)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 22050, 64, 128)    131200    \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 22050, 64, 128)    0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 22050, 128)        0         \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 22050, 128)        0         \n",
      "=================================================================\n",
      "Total params: 131,200\n",
      "Trainable params: 131,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 44, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 128)           512       \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 44, 128, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 40, 124, 128)      3328      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 20, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 20, 62, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 58, 128)       409728    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 29, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 29, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 25, 128)        409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 25, 128)        512       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1638528   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,481,162\n",
      "Trainable params: 2,480,138\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 44, 1024, 1)       0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              multiple                  131200    \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 10)                2481162   \n",
      "=================================================================\n",
      "Total params: 2,612,362\n",
      "Trainable params: 2,611,338\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "\n",
      "Fitting model...\n",
      "Epoch 1/101\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.2505 - model_2_loss: 0.1577 - model_1_loss: 1.0851\n",
      "F1 = 0.5203, ER = 0.5760 -  Best val F1s: 0.5203 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 2/101\n",
      "60000/60000 [==============================] - 50s 834us/step - loss: 0.2356 - model_2_loss: 0.1551 - model_1_loss: 0.9600\n",
      "F1 = 0.5279, ER = 0.5651 -  Best val F1s: 0.5279 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 3/101\n",
      "60000/60000 [==============================] - 50s 834us/step - loss: 0.2307 - model_2_loss: 0.1539 - model_1_loss: 0.9220\n",
      "F1 = 0.5282, ER = 0.5567 -  Best val F1s: 0.5282 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 4/101\n",
      "60000/60000 [==============================] - 50s 833us/step - loss: 0.2342 - model_2_loss: 0.1533 - model_1_loss: 0.9619\n",
      "F1 = 0.5377, ER = 0.5528 -  Best val F1s: 0.5377 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 5/101\n",
      "60000/60000 [==============================] - 50s 834us/step - loss: 0.2276 - model_2_loss: 0.1522 - model_1_loss: 0.9063\n",
      "F1 = 0.5250, ER = 0.5729 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 6/101\n",
      "60000/60000 [==============================] - 50s 834us/step - loss: 0.2309 - model_2_loss: 0.1519 - model_1_loss: 0.9421\n",
      "F1 = 0.5212, ER = 0.5788 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 7/101\n",
      "60000/60000 [==============================] - 50s 833us/step - loss: 0.2284 - model_2_loss: 0.1511 - model_1_loss: 0.9241\n",
      "F1 = 0.5139, ER = 0.5841 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 8/101\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.2271 - model_2_loss: 0.1507 - model_1_loss: 0.9143\n",
      "F1 = 0.5248, ER = 0.5692 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 9/101\n",
      "60000/60000 [==============================] - 50s 841us/step - loss: 0.2260 - model_2_loss: 0.1489 - model_1_loss: 0.9206\n",
      "F1 = 0.5265, ER = 0.5664 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 10/101\n",
      "60000/60000 [==============================] - 50s 834us/step - loss: 0.2272 - model_2_loss: 0.1481 - model_1_loss: 0.9396\n",
      "F1 = 0.5238, ER = 0.5761 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 11/101\n",
      "60000/60000 [==============================] - 50s 834us/step - loss: 0.2285 - model_2_loss: 0.1487 - model_1_loss: 0.9471\n",
      "F1 = 0.5169, ER = 0.5844 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 12/101\n",
      "60000/60000 [==============================] - 50s 834us/step - loss: 0.2191 - model_2_loss: 0.1464 - model_1_loss: 0.8733\n",
      "F1 = 0.5206, ER = 0.5765 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 13/101\n",
      "60000/60000 [==============================] - 50s 834us/step - loss: 0.2239 - model_2_loss: 0.1459 - model_1_loss: 0.9267\n",
      "F1 = 0.5331, ER = 0.5663 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 14/101\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.2205 - model_2_loss: 0.1450 - model_1_loss: 0.8994\n",
      "F1 = 0.5157, ER = 0.5795 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 15/101\n",
      "60000/60000 [==============================] - 50s 834us/step - loss: 0.2209 - model_2_loss: 0.1443 - model_1_loss: 0.9102\n",
      "F1 = 0.5169, ER = 0.5769 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 16/101\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.2222 - model_2_loss: 0.1454 - model_1_loss: 0.9136\n",
      "F1 = 0.5154, ER = 0.5749 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 17/101\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.2235 - model_2_loss: 0.1437 - model_1_loss: 0.9413\n",
      "F1 = 0.5324, ER = 0.5621 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 18/101\n",
      "60000/60000 [==============================] - 50s 834us/step - loss: 0.2206 - model_2_loss: 0.1432 - model_1_loss: 0.9170\n",
      "F1 = 0.5213, ER = 0.5675 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 19/101\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.2193 - model_2_loss: 0.1425 - model_1_loss: 0.9096\n",
      "F1 = 0.5281, ER = 0.5505 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 20/101\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.2225 - model_2_loss: 0.1426 - model_1_loss: 0.9417\n",
      "F1 = 0.5183, ER = 0.5694 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 21/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2178 - model_2_loss: 0.1417 - model_1_loss: 0.9027\n",
      "F1 = 0.5225, ER = 0.5651 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 22/101\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.2193 - model_2_loss: 0.1405 - model_1_loss: 0.9280\n",
      "F1 = 0.5218, ER = 0.5766 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 23/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2209 - model_2_loss: 0.1406 - model_1_loss: 0.9438\n",
      "F1 = 0.5317, ER = 0.5561 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 24/101\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.2171 - model_2_loss: 0.1401 - model_1_loss: 0.9101\n",
      "F1 = 0.5222, ER = 0.5682 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 25/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2140 - model_2_loss: 0.1383 - model_1_loss: 0.8953\n",
      "F1 = 0.5318, ER = 0.5629 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 26/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2194 - model_2_loss: 0.1383 - model_1_loss: 0.9494\n",
      "F1 = 0.5323, ER = 0.5530 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 27/101\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.2134 - model_2_loss: 0.1378 - model_1_loss: 0.8932\n",
      "F1 = 0.5294, ER = 0.5572 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 28/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2150 - model_2_loss: 0.1368 - model_1_loss: 0.9185\n",
      "F1 = 0.5235, ER = 0.5659 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 29/101\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.2144 - model_2_loss: 0.1364 - model_1_loss: 0.9163\n",
      "F1 = 0.5310, ER = 0.5503 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 30/101\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.2124 - model_2_loss: 0.1357 - model_1_loss: 0.9026\n",
      "F1 = 0.5257, ER = 0.5594 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 31/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2163 - model_2_loss: 0.1365 - model_1_loss: 0.9343\n",
      "F1 = 0.5253, ER = 0.5622 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 32/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2178 - model_2_loss: 0.1353 - model_1_loss: 0.9606\n",
      "F1 = 0.5287, ER = 0.5581 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 33/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2131 - model_2_loss: 0.1349 - model_1_loss: 0.9175\n",
      "F1 = 0.5314, ER = 0.5542 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 34/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2093 - model_2_loss: 0.1345 - model_1_loss: 0.8829\n",
      "F1 = 0.5329, ER = 0.5516 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 35/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2142 - model_2_loss: 0.1345 - model_1_loss: 0.9319\n",
      "F1 = 0.5266, ER = 0.5605 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 36/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2120 - model_2_loss: 0.1344 - model_1_loss: 0.9103\n",
      "F1 = 0.5269, ER = 0.5615 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 37/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2165 - model_2_loss: 0.1332 - model_1_loss: 0.9653\n",
      "F1 = 0.5238, ER = 0.5639 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 38/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2150 - model_2_loss: 0.1330 - model_1_loss: 0.9537\n",
      "F1 = 0.5290, ER = 0.5606 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 39/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2110 - model_2_loss: 0.1330 - model_1_loss: 0.9138\n",
      "F1 = 0.5248, ER = 0.5658 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 40/101\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.2120 - model_2_loss: 0.1321 - model_1_loss: 0.9314\n",
      "F1 = 0.5233, ER = 0.5667 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 41/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2114 - model_2_loss: 0.1313 - model_1_loss: 0.9318\n",
      "F1 = 0.5231, ER = 0.5689 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 42/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2077 - model_2_loss: 0.1308 - model_1_loss: 0.8994\n",
      "F1 = 0.5291, ER = 0.5641 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 43/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2089 - model_2_loss: 0.1314 - model_1_loss: 0.9066\n",
      "F1 = 0.5223, ER = 0.5678 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 44/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2060 - model_2_loss: 0.1299 - model_1_loss: 0.8916\n",
      "F1 = 0.5327, ER = 0.5598 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 45/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2083 - model_2_loss: 0.1300 - model_1_loss: 0.9139\n",
      "F1 = 0.5370, ER = 0.5465 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 46/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2128 - model_2_loss: 0.1296 - model_1_loss: 0.9615\n",
      "F1 = 0.5172, ER = 0.5772 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 47/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2103 - model_2_loss: 0.1294 - model_1_loss: 0.9386\n",
      "F1 = 0.5286, ER = 0.5611 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 48/101\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.2106 - model_2_loss: 0.1293 - model_1_loss: 0.9419\n",
      "F1 = 0.5232, ER = 0.5735 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 49/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2073 - model_2_loss: 0.1279 - model_1_loss: 0.9222\n",
      "F1 = 0.5353, ER = 0.5494 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 50/101\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.2043 - model_2_loss: 0.1276 - model_1_loss: 0.8942\n",
      "F1 = 0.5308, ER = 0.5499 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 51/101\n",
      "60000/60000 [==============================] - 50s 841us/step - loss: 0.2088 - model_2_loss: 0.1278 - model_1_loss: 0.9380\n",
      "F1 = 0.5310, ER = 0.5540 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 52/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2079 - model_2_loss: 0.1278 - model_1_loss: 0.9289\n",
      "F1 = 0.5267, ER = 0.5615 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 53/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2056 - model_2_loss: 0.1265 - model_1_loss: 0.9176\n",
      "F1 = 0.5218, ER = 0.5732 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 54/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2074 - model_2_loss: 0.1269 - model_1_loss: 0.9320\n",
      "F1 = 0.5118, ER = 0.5832 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 55/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2100 - model_2_loss: 0.1268 - model_1_loss: 0.9584\n",
      "F1 = 0.5322, ER = 0.5537 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 56/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2077 - model_2_loss: 0.1262 - model_1_loss: 0.9406\n",
      "F1 = 0.5209, ER = 0.5713 - Best val F1s: 0.5377 (3)\n",
      "\n",
      "Epoch 57/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2025 - model_2_loss: 0.1248 - model_1_loss: 0.9010\n",
      "F1 = 0.5389, ER = 0.5397 -  Best val F1s: 0.5389 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 58/101\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.2029 - model_2_loss: 0.1243 - model_1_loss: 0.9110\n",
      "F1 = 0.5254, ER = 0.5619 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 59/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2040 - model_2_loss: 0.1237 - model_1_loss: 0.9268\n",
      "F1 = 0.5275, ER = 0.5516 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 60/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2088 - model_2_loss: 0.1246 - model_1_loss: 0.9670\n",
      "F1 = 0.5213, ER = 0.5735 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 61/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2054 - model_2_loss: 0.1230 - model_1_loss: 0.9474\n",
      "F1 = 0.5298, ER = 0.5556 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 62/101\n",
      "60000/60000 [==============================] - 50s 838us/step - loss: 0.2025 - model_2_loss: 0.1234 - model_1_loss: 0.9142\n",
      "F1 = 0.5345, ER = 0.5464 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 63/101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.2057 - model_2_loss: 0.1233 - model_1_loss: 0.9476\n",
      "F1 = 0.5242, ER = 0.5662 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 64/101\n",
      "60000/60000 [==============================] - 50s 838us/step - loss: 0.2006 - model_2_loss: 0.1221 - model_1_loss: 0.9073\n",
      "F1 = 0.5353, ER = 0.5398 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 65/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2026 - model_2_loss: 0.1218 - model_1_loss: 0.9298\n",
      "F1 = 0.5389, ER = 0.5401 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 66/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2040 - model_2_loss: 0.1222 - model_1_loss: 0.9402\n",
      "F1 = 0.5286, ER = 0.5567 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 67/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2027 - model_2_loss: 0.1217 - model_1_loss: 0.9318\n",
      "F1 = 0.5241, ER = 0.5650 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 68/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2014 - model_2_loss: 0.1208 - model_1_loss: 0.9272\n",
      "F1 = 0.5278, ER = 0.5538 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 69/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2041 - model_2_loss: 0.1218 - model_1_loss: 0.9456\n",
      "F1 = 0.5257, ER = 0.5580 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 70/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2059 - model_2_loss: 0.1204 - model_1_loss: 0.9756\n",
      "F1 = 0.5285, ER = 0.5577 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 71/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1987 - model_2_loss: 0.1191 - model_1_loss: 0.9146\n",
      "F1 = 0.5271, ER = 0.5535 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 72/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1991 - model_2_loss: 0.1190 - model_1_loss: 0.9198\n",
      "F1 = 0.5179, ER = 0.5668 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 73/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2067 - model_2_loss: 0.1202 - model_1_loss: 0.9848\n",
      "F1 = 0.5245, ER = 0.5582 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 74/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1979 - model_2_loss: 0.1191 - model_1_loss: 0.9074\n",
      "F1 = 0.5242, ER = 0.5627 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 75/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2037 - model_2_loss: 0.1187 - model_1_loss: 0.9687\n",
      "F1 = 0.5343, ER = 0.5436 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 76/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1997 - model_2_loss: 0.1182 - model_1_loss: 0.9329\n",
      "F1 = 0.5208, ER = 0.5721 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 77/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2019 - model_2_loss: 0.1192 - model_1_loss: 0.9457\n",
      "F1 = 0.5365, ER = 0.5431 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 78/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2024 - model_2_loss: 0.1179 - model_1_loss: 0.9628\n",
      "F1 = 0.5277, ER = 0.5575 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 79/101\n",
      "60000/60000 [==============================] - 50s 838us/step - loss: 0.2002 - model_2_loss: 0.1185 - model_1_loss: 0.9360\n",
      "F1 = 0.5197, ER = 0.5597 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 80/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1984 - model_2_loss: 0.1170 - model_1_loss: 0.9311\n",
      "F1 = 0.5198, ER = 0.5640 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 81/101\n",
      "60000/60000 [==============================] - 50s 838us/step - loss: 0.2020 - model_2_loss: 0.1164 - model_1_loss: 0.9716\n",
      "F1 = 0.5379, ER = 0.5372 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 82/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1976 - model_2_loss: 0.1167 - model_1_loss: 0.9256\n",
      "F1 = 0.5305, ER = 0.5508 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 83/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1975 - model_2_loss: 0.1157 - model_1_loss: 0.9339\n",
      "F1 = 0.5339, ER = 0.5536 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 84/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1988 - model_2_loss: 0.1159 - model_1_loss: 0.9448\n",
      "F1 = 0.5237, ER = 0.5622 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 85/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2023 - model_2_loss: 0.1156 - model_1_loss: 0.9820\n",
      "F1 = 0.5205, ER = 0.5610 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 86/101\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.2003 - model_2_loss: 0.1154 - model_1_loss: 0.9642\n",
      "F1 = 0.5291, ER = 0.5527 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 87/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1979 - model_2_loss: 0.1155 - model_1_loss: 0.9396\n",
      "F1 = 0.5253, ER = 0.5566 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 88/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1929 - model_2_loss: 0.1141 - model_1_loss: 0.9024\n",
      "F1 = 0.5279, ER = 0.5488 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 89/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.2009 - model_2_loss: 0.1141 - model_1_loss: 0.9824\n",
      "F1 = 0.5211, ER = 0.5657 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 90/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1965 - model_2_loss: 0.1136 - model_1_loss: 0.9424\n",
      "F1 = 0.5318, ER = 0.5518 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 91/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1941 - model_2_loss: 0.1134 - model_1_loss: 0.9203\n",
      "F1 = 0.5194, ER = 0.5670 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 92/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1997 - model_2_loss: 0.1135 - model_1_loss: 0.9750\n",
      "F1 = 0.5254, ER = 0.5457 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 93/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1950 - model_2_loss: 0.1140 - model_1_loss: 0.9231\n",
      "F1 = 0.5151, ER = 0.5732 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 94/101\n",
      "60000/60000 [==============================] - 50s 838us/step - loss: 0.1923 - model_2_loss: 0.1133 - model_1_loss: 0.9029\n",
      "F1 = 0.5214, ER = 0.5626 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 95/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1982 - model_2_loss: 0.1130 - model_1_loss: 0.9652\n",
      "F1 = 0.5371, ER = 0.5398 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 96/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1934 - model_2_loss: 0.1120 - model_1_loss: 0.9263\n",
      "F1 = 0.5212, ER = 0.5586 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 97/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1975 - model_2_loss: 0.1131 - model_1_loss: 0.9566\n",
      "F1 = 0.5377, ER = 0.5329 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 98/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1967 - model_2_loss: 0.1124 - model_1_loss: 0.9548\n",
      "F1 = 0.5299, ER = 0.5408 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 99/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1920 - model_2_loss: 0.1123 - model_1_loss: 0.9088\n",
      "F1 = 0.5291, ER = 0.5481 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 100/101\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.1919 - model_2_loss: 0.1114 - model_1_loss: 0.9165\n",
      "F1 = 0.5266, ER = 0.5556 - Best val F1s: 0.5389 (56)\n",
      "\n",
      "Epoch 101/101\n",
      "60000/60000 [==============================] - 50s 838us/step - loss: 0.1945 - model_2_loss: 0.1111 - model_1_loss: 0.9447\n",
      "F1 = 0.5273, ER = 0.5544 - Best val F1s: 0.5389 (56)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "\n",
    "print('\\nBuilding model...')\n",
    "\n",
    "sequence_samples = int(sequence_time*sr)\n",
    "\n",
    "model_mel = SMel(mel_bands,sequence_samples,audio_win,audio_hop)  \n",
    "model_cnn = build_custom_cnn(n_freq_cnn=mel_bands, n_frames_cnn=sequence_frames,large_cnn=large_cnn)\n",
    "\n",
    "# Init with best weigths\n",
    "model_mel.load_weights(\"../../sed_endtoend/smel/weights_best.hdf5\")\n",
    "model_cnn.load_weights(\"../../sed_endtoend/cnn/weights_best.hdf5\")\n",
    "model = concatenate(sequence_frames,audio_win,model_cnn,model_mel)\n",
    "\n",
    "model_mel.summary()\n",
    "model_cnn.summary()\n",
    "model.summary()\n",
    "\n",
    "gamma=0.75\n",
    "\n",
    "opt = Adam_Multipliers(lr=learning_rate,multipliers=4*[lr_multiplier]+18*[1])\n",
    "\n",
    "if resume:\n",
    "    print('Loading best weights and resuming...')\n",
    "    weights_best_file = os.path.join(expfolder, 'weights_best.hdf5')\n",
    "    model.load_weights(weights_best_file)\n",
    "\n",
    "# Fit model\n",
    "print('\\nFitting model...')\n",
    "\n",
    "if resume:\n",
    "    f1s_best = resume_f1_best\n",
    "\n",
    "metrics_callback = MetricsCallback(x_val, [y_val,mel_val], 0, 0, os.path.join(expfolder, 'weights_best.hdf5'))\n",
    "csv_logger = CSVLogger('training.log')\n",
    "#losses_factor = K.variable(10.0)\n",
    "#w1 = K.variable(0.0)\n",
    "#w0 = K.variable(1.0)\n",
    "#bt_callback = BT_strategy(w0,w1, alpha=8, beta=1, gamma=gamma)\n",
    "\n",
    "model.compile(loss=['binary_crossentropy','mean_squared_error'],loss_weights=[0.9, 0.1],optimizer=opt)\n",
    "\n",
    "history = model.fit(x=x_train, y=[y_train,mel_train], batch_size=2*batch_size,\n",
    "                            epochs=epochs, verbose=fit_verbose,\n",
    "                            validation_split=0.0,\n",
    "                            shuffle=True,\n",
    "                            callbacks=[metrics_callback,csv_logger])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
